{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import ask\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import json \n",
    "\n",
    "output = ask(\"What is the weather in Tokyo?\", \"2024-11-25\", \"jp\", False)\n",
    "\n",
    "def get_answer_text(response):\n",
    "\n",
    "    lines = response.split('\\n')\n",
    "    answer = []\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            # line = line.decode('utf-8')\n",
    "            if line.startswith('data:'):\n",
    "                try:\n",
    "                    data = json.loads(line[5:])\n",
    "                    if data['type'] == 'llm':\n",
    "                        answer.append(data['text'])\n",
    "                except:\n",
    "                    pass\n",
    "    return ''.join(answer)\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def read_stream(response):\n",
    "    text = \"\"\n",
    "    async for chunk in response.body_iterator:\n",
    "        if isinstance(chunk, bytes):\n",
    "            text += chunk.decode()\n",
    "        else:\n",
    "            text += chunk\n",
    "    return text\n",
    "\n",
    "# Run the async function\n",
    "text = asyncio.run(read_stream(output))\n",
    "print(text)\n",
    "\n",
    "final_text = get_answer_text(text)\n",
    "print(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_qa_api import SentientSearchQA\n",
    "\n",
    "api = SentientSearchQA()\n",
    "\n",
    "final_text = api.chat_completion(\"What is the most valuable company in the world as of today?\")\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/salah/SentientSearch/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from semantic_router.encoders import CohereEncoder\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "cohere_encoder = CohereEncoder(cohere_api_key=COHERE_API_KEY, input_type='search_document',\n",
    "                        name='embed-multilingual-v3.0',)\n",
    "\n",
    "cohere_chunker = StatisticalChunker(encoder=cohere_encoder, max_split_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CohereEncoder(name='embed-multilingual-v3.0', score_threshold=0.3, type='cohere', client=<cohere.client.Client object at 0x7f7f8876d210>, input_type='search_document')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohere_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia_embedder import NvidiaEncoder\n",
    "\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "nvidia_encoder = NvidiaEncoder(input_type='query')\n",
    "nvidia_chunker = StatisticalChunker(encoder=nvidia_encoder, max_split_tokens=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "docs = [\"What is the weather in Tokyo?\", \"How much money do I need to retire?\", \"What is the capital of France?\"]\n",
    "embeddings = nvidia_encoder(docs)\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = cohere_encoder(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
